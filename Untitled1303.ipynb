{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94e028c-c16e-4dd6-a261-796250e92ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Only one label from folders: misc\n",
      "[INFO] Falling back to filename-based labels…\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_features.csv\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_feature_corr_heatmap.png\n",
      "[WARN] Dropping rare classes (<2 samples): ['Camille Pissarro', 'Lubo Kristek', 'Oscar Florianus Bluemner', 'Paul Nash', 'Salvador Dali']\n",
      "[INFO] Classes after filtering (4): ['Edvard Munch', 'Katsushika Hokusai', 'Leonardo Da Vinci', 'Vincent Van Gogh']\n",
      "[WARN] Stratified split failed (The test_size = 3 should be greater or equal to the number of classes = 4); using non-stratified split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_accuracy_over_epochs.png\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_accuracy_over_epochs.csv\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_confusion_matrix.png\n",
      "[SAVED] C:\\Users\\sagni\\Downloads\\Artify AI\\artify_classification_report.txt\n",
      "\n",
      "[DONE] All artifacts saved in: C:\\Users\\sagni\\Downloads\\Artify AI\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ArtifyAI — Heatmap + Accuracy Graph + CSV (All-in-One, fixed .str.strip)\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# Paths / Config\n",
    "# ----------------------------\n",
    "IN_ROOT = Path(r\"C:\\Users\\sagni\\Downloads\\Artify AI\\archive\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\Artify AI\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES_CSV = OUT_DIR / \"artify_features.csv\"\n",
    "HEATMAP_PNG  = OUT_DIR / \"artify_feature_corr_heatmap.png\"\n",
    "ACC_PNG      = OUT_DIR / \"artify_accuracy_over_epochs.png\"\n",
    "ACC_CSV      = OUT_DIR / \"artify_accuracy_over_epochs.csv\"\n",
    "CM_PNG       = OUT_DIR / \"artify_confusion_matrix.png\"\n",
    "REPORT_TXT   = OUT_DIR / \"artify_classification_report.txt\"\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "HIST_BINS = 16\n",
    "EDGE_RESIZE = 256\n",
    "EPOCHS = 12\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "MIN_SAMPLES_PER_CLASS = 2\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def list_images(root: Path):\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def extract_features_one(path: Path) -> Dict[str, Any]:\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "            w, h = im.size\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "\n",
    "        r, g, b = arr[..., 0], arr[..., 1], arr[..., 2]\n",
    "        gray = rgb2gray(arr)  # [0,1]\n",
    "\n",
    "        # basic geometry + color stats\n",
    "        feats = {\n",
    "            \"width\": float(w),\n",
    "            \"height\": float(h),\n",
    "            \"aspect_ratio\": float(w / h) if h else np.nan,\n",
    "            \"mean_r\": float(r.mean()), \"mean_g\": float(g.mean()), \"mean_b\": float(b.mean()),\n",
    "            \"std_r\": float(r.std()),  \"std_g\": float(g.std()),  \"std_b\": float(b.std()),\n",
    "            \"brightness\": float(gray.mean()),\n",
    "            \"contrast\": float(gray.std()),\n",
    "        }\n",
    "\n",
    "        # edge density\n",
    "        if min(h, w) > 0 and min(h, w) != EDGE_RESIZE:\n",
    "            scale = EDGE_RESIZE / min(h, w)\n",
    "            gray_small = np.asarray(\n",
    "                Image.fromarray((gray * 255).astype(np.uint8)).resize((int(w * scale), int(h * scale)))\n",
    "            ) / 255.0\n",
    "        else:\n",
    "            gray_small = gray\n",
    "        feats[\"edge_density\"] = float(canny(gray_small, sigma=1.5).mean())\n",
    "\n",
    "        # grayscale histogram\n",
    "        hist, _ = np.histogram((gray * 255.0).astype(np.uint8), bins=HIST_BINS, range=(0, 255))\n",
    "        hist = (hist.astype(np.float32) / (hist.sum() + 1e-9)).tolist()\n",
    "        for i, v in enumerate(hist):\n",
    "            feats[f\"hist_{i:02d}\"] = float(v)\n",
    "\n",
    "        return feats\n",
    "\n",
    "    except UnidentifiedImageError:\n",
    "        base = {\n",
    "            \"width\": np.nan, \"height\": np.nan, \"aspect_ratio\": np.nan,\n",
    "            \"mean_r\": np.nan, \"mean_g\": np.nan, \"mean_b\": np.nan,\n",
    "            \"std_r\": np.nan, \"std_g\": np.nan, \"std_b\": np.nan,\n",
    "            \"brightness\": np.nan, \"contrast\": np.nan, \"edge_density\": np.nan,\n",
    "        }\n",
    "        for i in range(HIST_BINS):\n",
    "            base[f\"hist_{i:02d}\"] = np.nan\n",
    "        base[\"error\"] = \"unidentified_image\"\n",
    "        return base\n",
    "\n",
    "def derive_label_rel_first(root: Path, path: Path) -> str:\n",
    "    rel = path.relative_to(root)\n",
    "    parts = rel.parts\n",
    "    return parts[0] if len(parts) >= 2 else \"misc\"\n",
    "\n",
    "def derive_label_from_filename(name: str) -> str:\n",
    "    stem = Path(name).stem\n",
    "    for sep in (\"_\", \"-\"):\n",
    "        if sep in stem:\n",
    "            return stem.split(sep)[0]\n",
    "    return stem\n",
    "\n",
    "def build_manifest(root: Path) -> pd.DataFrame:\n",
    "    files = list_images(root)\n",
    "    rows = []\n",
    "    for i, p in enumerate(files, 1):\n",
    "        feats = extract_features_one(p)\n",
    "        rows.append({\n",
    "            \"label\": derive_label_rel_first(root, p),\n",
    "            \"filename\": p.name,\n",
    "            \"relpath\": str(p.relative_to(root)),\n",
    "            \"abspath\": str(p.resolve()),\n",
    "            **feats\n",
    "        })\n",
    "        if i % 500 == 0:\n",
    "            print(f\"[SCAN] {i}/{len(files)}\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.dropna(subset=[\"width\", \"height\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Scan + features → CSV\n",
    "# ----------------------------\n",
    "df = build_manifest(IN_ROOT)\n",
    "if df.empty:\n",
    "    raise SystemExit(\"No images found. Check IN_ROOT path and file types.\")\n",
    "\n",
    "# Fallback to filename-based labels if only one folder-label exists\n",
    "labels_before = sorted(df[\"label\"].unique().tolist())\n",
    "if len(labels_before) == 1:\n",
    "    print(f\"[WARN] Only one label from folders: {labels_before[0]}\")\n",
    "    print(\"[INFO] Falling back to filename-based labels…\")\n",
    "    df[\"label\"] = df[\"filename\"].map(derive_label_from_filename)\n",
    "\n",
    "# ✅ FIX: normalize labels using .str.strip()\n",
    "df[\"label\"] = df[\"label\"].astype(str).str.strip()\n",
    "\n",
    "# Save features CSV (always)\n",
    "FEATURES_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(FEATURES_CSV, index=False)\n",
    "print(f\"[SAVED] {FEATURES_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Correlation heatmap (numeric-only)\n",
    "# ----------------------------\n",
    "num_cols = [c for c in df.columns\n",
    "            if c not in {\"label\", \"filename\", \"relpath\", \"abspath\", \"error\"}\n",
    "            and pd.api.types.is_numeric_dtype(df[c])]\n",
    "corr = df[num_cols].corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "im = plt.imshow(corr.values, aspect='auto')\n",
    "plt.xticks(range(corr.shape[1]), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(corr.shape[0]), corr.index)\n",
    "plt.title(\"ArtifyAI: Feature Correlation Heatmap\")\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(HEATMAP_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {HEATMAP_PNG}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Drop rare classes (< MIN_SAMPLES_PER_CLASS)\n",
    "# ----------------------------\n",
    "vc = df[\"label\"].value_counts()\n",
    "rare = vc[vc < MIN_SAMPLES_PER_CLASS]\n",
    "if not rare.empty:\n",
    "    print(f\"[WARN] Dropping rare classes (<{MIN_SAMPLES_PER_CLASS} samples): {list(rare.index)}\")\n",
    "    df = df[~df[\"label\"].isin(rare.index)].reset_index(drop=True)\n",
    "\n",
    "classes = sorted(df[\"label\"].unique().tolist())\n",
    "print(f\"[INFO] Classes after filtering ({len(classes)}): {classes}\")\n",
    "if len(classes) < 2:\n",
    "    print(\"\\n[SKIP] Not enough classes after filtering. \"\n",
    "          \"Accuracy graph & CM require >= 2 classes with >= 2 samples each.\")\n",
    "    raise SystemExit(0)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Train/Test split (stratified → fallback)\n",
    "# ----------------------------\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"label\"].astype(str))\n",
    "X = df[num_cols].astype(float).values\n",
    "\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"[WARN] Stratified split failed ({e}); using non-stratified split.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=None\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Train over epochs (SGD + Standardize)\n",
    "# ----------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", SGDClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        alpha=1e-4,\n",
    "        max_iter=1,          # manual epochs\n",
    "        learning_rate=\"optimal\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        warm_start=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "train_acc, test_acc = [], []\n",
    "for ep in range(EPOCHS):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_tr_pred = pipe.predict(X_train)\n",
    "    y_te_pred = pipe.predict(X_test)\n",
    "    train_acc.append(accuracy_score(y_train, y_tr_pred))\n",
    "    test_acc.append(accuracy_score(y_test, y_te_pred))\n",
    "\n",
    "# Accuracy curve + CSV\n",
    "plt.figure(figsize=(8, 4.8))\n",
    "plt.plot(range(1, EPOCHS+1), train_acc, marker='o', label=\"Train Accuracy\")\n",
    "plt.plot(range(1, EPOCHS+1), test_acc,  marker='s', label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"ArtifyAI: Accuracy over Epochs (Engineered Features + SGD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(ACC_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {ACC_PNG}\")\n",
    "\n",
    "pd.DataFrame({\"epoch\": range(1, EPOCHS+1),\n",
    "              \"train_accuracy\": train_acc,\n",
    "              \"test_accuracy\": test_acc}).to_csv(ACC_CSV, index=False)\n",
    "print(f\"[SAVED] {ACC_CSV}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Confusion matrix + robust report\n",
    "# ----------------------------\n",
    "y_pred = pipe.predict(X_test)\n",
    "labels_present = np.unique(np.concatenate([y_test, y_pred]))\n",
    "class_names_present = [le.classes_[i] for i in labels_present]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels_present)\n",
    "plt.figure(figsize=(max(7.5, min(14, 0.45*len(class_names_present)+4)), 6.5))\n",
    "im = plt.imshow(cm, aspect='auto')\n",
    "plt.title(\"ArtifyAI: Confusion Matrix (Styles)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.colorbar(im)\n",
    "plt.xticks(range(len(class_names_present)), class_names_present, rotation=45, ha='right')\n",
    "plt.yticks(range(len(class_names_present)), class_names_present)\n",
    "plt.tight_layout()\n",
    "plt.savefig(CM_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(f\"[SAVED] {CM_PNG}\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_test, y_pred,\n",
    "    labels=labels_present,\n",
    "    target_names=class_names_present,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    ")\n",
    "with open(REPORT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== ArtifyAI: Engineered Features + SGDClassifier ===\\n\\n\")\n",
    "    f.write(report + \"\\n\")\n",
    "print(f\"[SAVED] {REPORT_TXT}\")\n",
    "\n",
    "print(\"\\n[DONE] All artifacts saved in:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad31d3-2e42-4e81-8efe-9016e14809fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
