{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa0907d-c1cf-43d0-93b4-6e659257e515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scanned: 18 images\n",
      "[INFO] Columns: ['artist', 'filename', 'relpath', 'abspath', 'ext', 'size_bytes', 'sha256_head', 'width', 'height', 'mode', 'format', 'dpi_x', 'dpi_y']\n",
      "[INFO] Head:\n",
      "     artist                                     filename  \\\n",
      "0  archive  Camille Pissarro - Boulevard Montmartre.jpg   \n",
      "1  archive                   Edvard Munch - Anxiety.jpg   \n",
      "2  archive                Edvard Munch - The Scream.jpg   \n",
      "\n",
      "                                       relpath  \\\n",
      "0  Camille Pissarro - Boulevard Montmartre.jpg   \n",
      "1                   Edvard Munch - Anxiety.jpg   \n",
      "2                Edvard Munch - The Scream.jpg   \n",
      "\n",
      "                                             abspath   ext  size_bytes  \\\n",
      "0  C:\\Users\\sagni\\Downloads\\Artify AI\\archive\\Cam...  .jpg     3436910   \n",
      "1  C:\\Users\\sagni\\Downloads\\Artify AI\\archive\\Edv...  .jpg    11238116   \n",
      "2  C:\\Users\\sagni\\Downloads\\Artify AI\\archive\\Edv...  .jpg    37765818   \n",
      "\n",
      "                                         sha256_head  width  height mode  \\\n",
      "0  edf2945abf188c4d183e21eb5c69c5a82744533c31ff93...   3380    2696  RGB   \n",
      "1  42bbbfe24524bab88e54140a1553bd4676a9155dd6ef95...   5220    6734  RGB   \n",
      "2  58b8b799a93d02f5aa79d7aa487958784030f382ce71b8...   4323    5546  RGB   \n",
      "\n",
      "  format  dpi_x  dpi_y  \n",
      "0   JPEG    NaN    NaN  \n",
      "1   JPEG    NaN    NaN  \n",
      "2   JPEG  300.0  300.0  \n",
      "[WRITE] Pickle -> C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.pkl\n",
      "[INFO] HDF5 min_itemsize: {'artist': 71, 'filename': 116, 'relpath': 116, 'abspath': 159, 'ext': 68, 'sha256_head': 128, 'mode': 67, 'format': 68}\n",
      "[WRITE] HDF5   -> C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.h5\n",
      "[WRITE] JSON   -> C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.json\n",
      "[INFO] Writing full YAML with 18 rows (can be large).\n",
      "[WRITE] YAML   -> C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.yaml\n",
      "\n",
      "[DONE] Files saved in: C:\\Users\\sagni\\Downloads\\Artify AI\n",
      " - C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.pkl\n",
      " - C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.h5 (if created)\n",
      " - C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.json\n",
      " - C:\\Users\\sagni\\Downloads\\Artify AI\\artify_manifest.yaml\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ArtifyAI — Archive Scanner → H5 / PKL / YAML / JSON\n",
    "# Scans images, builds a manifest (one row per image), and\n",
    "# saves robustly with large-text-safe HDF5 + streaming JSON.\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# ---------- Optional YAML ----------\n",
    "try:\n",
    "    import yaml\n",
    "    HAVE_YAML = True\n",
    "except Exception:\n",
    "    HAVE_YAML = False\n",
    "    print(\"[WARN] PyYAML not installed; YAML output will be skipped.\")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "IN_ROOT = Path(r\"C:\\Users\\sagni\\Downloads\\Artify AI\\archive\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\Artify AI\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PKL_PATH  = OUT_DIR / \"artify_manifest.pkl\"\n",
    "H5_PATH   = OUT_DIR / \"artify_manifest.h5\"\n",
    "JSON_PATH = OUT_DIR / \"artify_manifest.json\"\n",
    "YAML_PATH = OUT_DIR / \"artify_manifest.yaml\"   # subset by default; see YAML_MAX_ROWS\n",
    "\n",
    "# ---------- Config ----------\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\", \".gif\"}\n",
    "SHA256_HEAD_BYTES = 65536   # 64KB for quick fingerprint\n",
    "YAML_MAX_ROWS = 5000        # set to None for full YAML (can be very large!)\n",
    "\n",
    "# ==========================================================\n",
    "# Helpers\n",
    "# ==========================================================\n",
    "def list_images(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        print(f\"[ERROR] Input folder not found: {root}\")\n",
    "        return []\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def sha256_head(path: Path, nbytes: int = SHA256_HEAD_BYTES) -> str:\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            chunk = f.read(nbytes)\n",
    "            h.update(chunk)\n",
    "        return h.hexdigest()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def safe_image_info(path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract lightweight info; do NOT load the whole image into memory.\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        \"width\": np.nan,\n",
    "        \"height\": np.nan,\n",
    "        \"mode\": None,\n",
    "        \"format\": None,\n",
    "        \"dpi_x\": None,\n",
    "        \"dpi_y\": None,\n",
    "    }\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            info[\"width\"], info[\"height\"] = im.size\n",
    "            info[\"mode\"] = im.mode\n",
    "            info[\"format\"] = im.format\n",
    "            # DPI (if present)\n",
    "            dpi = im.info.get(\"dpi\", None)\n",
    "            if isinstance(dpi, tuple) and len(dpi) >= 2:\n",
    "                info[\"dpi_x\"], info[\"dpi_y\"] = dpi[0], dpi[1]\n",
    "            elif isinstance(dpi, (int, float)):\n",
    "                info[\"dpi_x\"] = info[\"dpi_y\"] = dpi\n",
    "    except UnidentifiedImageError:\n",
    "        info[\"format\"] = \"UNREADABLE\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return info\n",
    "\n",
    "def scan_archive(root: Path) -> pd.DataFrame:\n",
    "    files = list_images(root)\n",
    "    rows = []\n",
    "    for i, p in enumerate(files, 1):\n",
    "        try:\n",
    "            stat = p.stat()\n",
    "            img = safe_image_info(p)\n",
    "            # Use parent folder as \"artist/style\" label (common layout)\n",
    "            artist = p.parent.name\n",
    "            rows.append({\n",
    "                \"artist\": artist,\n",
    "                \"filename\": p.name,\n",
    "                \"relpath\": str(p.relative_to(root)),\n",
    "                \"abspath\": str(p.resolve()),\n",
    "                \"ext\": p.suffix.lower(),\n",
    "                \"size_bytes\": stat.st_size,\n",
    "                \"sha256_head\": sha256_head(p),\n",
    "                **img,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            rows.append({\n",
    "                \"artist\": p.parent.name,\n",
    "                \"filename\": p.name,\n",
    "                \"relpath\": str(p.relative_to(root)),\n",
    "                \"abspath\": str(p.resolve()),\n",
    "                \"ext\": p.suffix.lower(),\n",
    "                \"size_bytes\": None,\n",
    "                \"sha256_head\": \"\",\n",
    "                \"width\": np.nan, \"height\": np.nan,\n",
    "                \"mode\": None, \"format\": None, \"dpi_x\": None, \"dpi_y\": None,\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "        if i % 500 == 0:\n",
    "            print(f\"[SCAN] {i}/{len(files)} files...\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values([\"artist\", \"filename\"]).reset_index(drop=True)\n",
    "    print(f\"[INFO] Scanned: {len(df)} images\")\n",
    "    return df\n",
    "\n",
    "def coerce_for_hdf(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df_in.copy()\n",
    "    # object -> str\n",
    "    for c in g.select_dtypes(include=[\"object\"]).columns:\n",
    "        g[c] = g[c].astype(str)\n",
    "    # normalize numerics\n",
    "    for c in g.columns:\n",
    "        s = g[c]\n",
    "        if pd.api.types.is_integer_dtype(s):\n",
    "            g[c] = s.astype(\"int64\", copy=False)\n",
    "        elif pd.api.types.is_float_dtype(s):\n",
    "            g[c] = s.astype(\"float64\", copy=False)\n",
    "        elif pd.api.types.is_bool_dtype(s):\n",
    "            g[c] = s.astype(bool, copy=False)\n",
    "    return g\n",
    "\n",
    "def build_min_itemsize(df_in: pd.DataFrame, cap: int = 65500, headroom: int = 64) -> Dict[str, int]:\n",
    "    sizes = {}\n",
    "    for c in df_in.select_dtypes(include=[\"object\"]).columns:\n",
    "        try:\n",
    "            max_len = int(df_in[c].astype(str).str.len().max() or 0)\n",
    "        except Exception:\n",
    "            max_len = 0\n",
    "        size = min(cap, max_len + headroom)\n",
    "        if size > 0:\n",
    "            sizes[c] = size\n",
    "    return sizes\n",
    "\n",
    "def to_py_scalar(v):\n",
    "    \"\"\"Convert numpy/pandas scalars to plain Python for JSON/YAML.\"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, (np.integer,)):\n",
    "        return int(v)\n",
    "    if isinstance(v, (np.floating,)):\n",
    "        return None if np.isnan(v) else float(v)\n",
    "    if isinstance(v, (np.bool_,)):\n",
    "        return bool(v)\n",
    "    return v\n",
    "\n",
    "# ==========================================================\n",
    "# Run\n",
    "# ==========================================================\n",
    "df = scan_archive(IN_ROOT)\n",
    "if df.empty:\n",
    "    raise SystemExit(\"No images found. Check input path or extensions.\")\n",
    "\n",
    "print(\"[INFO] Columns:\", list(df.columns))\n",
    "print(\"[INFO] Head:\\n\", df.head(3))\n",
    "\n",
    "# ---------- 1) Pickle ----------\n",
    "print(f\"[WRITE] Pickle -> {PKL_PATH}\")\n",
    "df.to_pickle(PKL_PATH)\n",
    "\n",
    "# ---------- 2) HDF5 (with per-column min_itemsize) ----------\n",
    "try:\n",
    "    df_h5 = coerce_for_hdf(df)\n",
    "    min_itemsize = build_min_itemsize(df_h5)\n",
    "    print(\"[INFO] HDF5 min_itemsize:\", min_itemsize)\n",
    "    if H5_PATH.exists():\n",
    "        try: H5_PATH.unlink()\n",
    "        except Exception: pass\n",
    "    print(f\"[WRITE] HDF5   -> {H5_PATH}\")\n",
    "    df_h5.to_hdf(\n",
    "        H5_PATH,\n",
    "        key=\"images\",\n",
    "        mode=\"w\",\n",
    "        format=\"table\",\n",
    "        complib=\"blosc:zstd\",\n",
    "        complevel=5,\n",
    "        min_itemsize=min_itemsize,\n",
    "        data_columns=[\"artist\", \"ext\", \"format\"]  # queryable columns\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Could not write HDF5: {e}\\n       Hint: pip install tables (64-bit) and ensure enough disk space.\")\n",
    "\n",
    "# ---------- 3) JSON (streaming valid array) ----------\n",
    "# Writes a proper JSON array without loading entire data to memory.\n",
    "print(f\"[WRITE] JSON   -> {JSON_PATH}\")\n",
    "with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        rec = {k: to_py_scalar(v) for k, v in row.to_dict().items()}\n",
    "        f.write(json.dumps(rec, ensure_ascii=False))\n",
    "        if i != len(df) - 1:\n",
    "            f.write(\",\\n\")\n",
    "    f.write(\"\\n]\\n\")\n",
    "\n",
    "# ---------- 4) YAML (cap rows to keep file reasonable) ----------\n",
    "if HAVE_YAML:\n",
    "    try:\n",
    "        if YAML_MAX_ROWS is None or YAML_MAX_ROWS >= len(df):\n",
    "            subset = df\n",
    "            print(f\"[INFO] Writing full YAML with {len(df)} rows (can be large).\")\n",
    "        else:\n",
    "            subset = df.iloc[:YAML_MAX_ROWS]\n",
    "            print(f\"[INFO] Writing YAML subset of {len(subset)} rows (YAML_MAX_ROWS={YAML_MAX_ROWS}).\")\n",
    "\n",
    "        subset_records = []\n",
    "        for _, row in subset.iterrows():\n",
    "            rec = {k: to_py_scalar(v) for k, v in row.to_dict().items()}\n",
    "            # ensure only JSON/YAML-safe scalar types\n",
    "            for k, v in list(rec.items()):\n",
    "                if not isinstance(v, (str, int, float, bool)) and v is not None:\n",
    "                    rec[k] = str(v)\n",
    "            subset_records.append(rec)\n",
    "\n",
    "        print(f\"[WRITE] YAML   -> {YAML_PATH}\")\n",
    "        with open(YAML_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.safe_dump(subset_records, f, allow_unicode=True, sort_keys=False)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write YAML: {e}\\n       Tip: set YAML_MAX_ROWS lower or write to a larger drive.\")\n",
    "else:\n",
    "    print(\"[INFO] Skipping YAML (PyYAML not installed).\")\n",
    "\n",
    "print(\"\\n[DONE] Files saved in:\", OUT_DIR)\n",
    "print(\" -\", PKL_PATH)\n",
    "print(\" -\", H5_PATH, \"(if created)\")\n",
    "print(\" -\", JSON_PATH)\n",
    "if HAVE_YAML:\n",
    "    print(\" -\", YAML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e0ac8-e378-4153-bff0-58a36a58daed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
